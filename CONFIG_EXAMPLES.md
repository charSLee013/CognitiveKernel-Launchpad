# Cognitive Kernel-Pro é…ç½®ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›å®Œæ•´çš„TOMLé…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨æ ¹æ®ä¸åŒçš„ä½¿ç”¨åœºæ™¯è¿›è¡Œé…ç½®ã€‚

## ğŸ“‹ é…ç½®é€‰é¡¹æ€»è§ˆ

### å¿«é€Ÿå¼€å§‹é€‰é¡¹

| æ–¹æ³• | é€‚ç”¨åœºæ™¯ | é…ç½®å¤æ‚åº¦ | æ¨èæŒ‡æ•° |
|------|----------|------------|----------|
| **ç¯å¢ƒå˜é‡** | æ–°ç”¨æˆ·å¿«é€Ÿå¼€å§‹ | â­ | â­â­â­â­â­ |
| **æœ€å°é…ç½®** | æ ‡å‡†ä½¿ç”¨ | â­â­ | â­â­â­â­ |
| **å…¨é¢é…ç½®** | é«˜çº§å®šåˆ¶ | â­â­â­â­â­ | â­â­â­ |

## ğŸš€ ç¯å¢ƒå˜é‡æ–¹å¼ (æ¨èæ–°ç”¨æˆ·)

### æ— éœ€é…ç½®æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼š

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_BASE="https://api.openai.com/v1/chat/completions"
export OPENAI_API_KEY="your-api-key-here"
export OPENAI_API_MODEL="gpt-4o-mini"

# è¿è¡Œ
python -m ck_pro --input "What is AI?"
```

### ä¼˜åŠ¿
- âœ… **é›¶é…ç½®**ï¼šæ— éœ€åˆ›å»ºä»»ä½•æ–‡ä»¶
- âœ… **å¿«é€Ÿå¯åŠ¨**ï¼š5ç§’å†…å¼€å§‹ä½¿ç”¨
- âœ… **å®¹å™¨å‹å¥½**ï¼šå®Œç¾æ”¯æŒDocker/K8s
- âœ… **å®‰å…¨ç®¡ç†**ï¼šæ•æ„Ÿä¿¡æ¯ç¯å¢ƒå˜é‡ç®¡ç†

## ğŸ“ æœ€å°é…ç½®æ–‡ä»¶

é€‚ç”¨äºå¤§å¤šæ•°æ ‡å‡†ä½¿ç”¨åœºæ™¯ï¼Œåªéœ€è¦é…ç½®æ ¸å¿ƒç»„ä»¶ã€‚

```toml
# config.minimal.toml
[ck.model]
call_target = "https://api.openai.com/v1/chat/completions"
api_key = "your-api-key-here"
model = "gpt-4o-mini"

[ck.model.extract_body]
temperature = 0.6
max_tokens = 4000

[ck]
max_steps = 16
max_time_limit = 600

[search]
backend = "duckduckgo"
```

### ä½¿ç”¨æ–¹æ³•
```bash
cp config.minimal.toml config.toml
# ç¼–è¾‘config.tomlä¸­çš„APIå¯†é’¥
python -m ck_pro --input "What is AI?"
```

## âš™ï¸ å…¨é¢é…ç½®æ–‡ä»¶

åŒ…å«æ‰€æœ‰å¯ç”¨é…ç½®é€‰é¡¹ï¼Œé€‚ç”¨äºéœ€è¦å®Œå…¨æ§åˆ¶ç³»ç»Ÿçš„åœºæ™¯ã€‚

```toml
# config.comprehensive.toml - å®Œæ•´ç¤ºä¾‹è§åŒç›®å½•æ–‡ä»¶
[ck]
name = "ck_agent"
description = "Cognitive Kernel, an initial autopilot system."
max_steps = 16
max_time_limit = 6000
recent_steps = 5
obs_max_token = 8192
exec_timeout_with_call = 1000
exec_timeout_wo_call = 200
end_template = "more"

[ck.model]
call_target = "https://api.openai.com/v1/chat/completions"
api_key = "your-openai-api-key"
model = "gpt-4o-mini"
request_timeout = 600
max_retry_times = 5
max_token_num = 20000

# ... æ›´å¤šé…ç½®é€‰é¡¹è§ config.comprehensive.toml
```

## ğŸ”§ é…ç½®è¯´æ˜

### æ ¸å¿ƒé…ç½® [ck]

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `name` | "ck_agent" | ä»£ç†åç§° |
| `max_steps` | 16 | æœ€å¤§æ¨ç†æ­¥éª¤æ•° |
| `max_time_limit` | 6000 | æœ€å¤§æ‰§è¡Œæ—¶é—´(ç§’) |
| `end_template` | "more" | ç»“æŸæ¨¡æ¿è¯¦ç»†ç¨‹åº¦ |

### æ¨¡å‹é…ç½® [ck.model]

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `call_target` | string | APIç«¯ç‚¹URL |
| `api_key` | string | APIå¯†é’¥ |
| `model` | string | æ¨¡å‹åç§° |
| `request_timeout` | int | è¯·æ±‚è¶…æ—¶æ—¶é—´ |
| `max_retry_times` | int | æœ€å¤§é‡è¯•æ¬¡æ•° |

### Webä»£ç†é…ç½® [web]

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `max_steps` | 20 | Webä»»åŠ¡æœ€å¤§æ­¥éª¤æ•° |
| `use_multimodal` | "auto" | æ˜¯å¦ä½¿ç”¨å¤šæ¨¡æ€(off/yes/auto) |

### æ–‡ä»¶ä»£ç†é…ç½® [file]

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `max_steps` | 16 | æ–‡ä»¶å¤„ç†æœ€å¤§æ­¥éª¤æ•° |
| `max_file_read_tokens` | 3000 | æ–‡ä»¶è¯»å–æœ€å¤§tokenæ•° |
| `max_file_screenshots` | 2 | æ–‡ä»¶æˆªå›¾æœ€å¤§æ•°é‡ |

### æ—¥å¿—é…ç½® [logging]

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `console_level` | "INFO" | æ§åˆ¶å°æ—¥å¿—çº§åˆ« |
| `log_dir` | "logs" | æ—¥å¿—ç›®å½• |
| `session_logs` | true | æ˜¯å¦å¯ç”¨ä¼šè¯æ—¥å¿— |

### æœç´¢é…ç½® [search]

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `backend` | "duckduckgo" | æœç´¢å¼•æ“(duckduckgo/google) |

## ğŸ¯ ä¼˜å…ˆçº§é¡ºåº

é…ç½®å€¼çš„ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼š

1. **TOMLé…ç½®æ–‡ä»¶** - æœ€é«˜ä¼˜å…ˆçº§
2. **ç»§æ‰¿æœºåˆ¶** - å­ç»„ä»¶ç»§æ‰¿çˆ¶ç»„ä»¶è®¾ç½®
3. **ç¯å¢ƒå˜é‡** - ä¸­ç­‰ä¼˜å…ˆçº§
4. **ç¡¬ç¼–ç é»˜è®¤å€¼** - æœ€ä½ä¼˜å…ˆçº§

### ç»§æ‰¿ç¤ºä¾‹

```toml
[ck.model]
call_target = "https://api.openai.com/v1/chat/completions"
api_key = "shared-key"

[web.model]
# è‡ªåŠ¨ç»§æ‰¿ call_target å’Œ api_key
model = "gpt-4-vision"  # åªè¦†ç›–æ¨¡å‹åç§°

[file.model]
call_target = "https://different-api.com"  # è¦†ç›–ç»§æ‰¿çš„è®¾ç½®
api_key = "different-key"  # è¦†ç›–ç»§æ‰¿çš„è®¾ç½®
model = "claude-3-sonnet"  # æŒ‡å®šä¸åŒæ¨¡å‹
```

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

### åœºæ™¯1: æ–°ç”¨æˆ·å¿«é€Ÿå¼€å§‹
```bash
# æ–¹å¼1: ç¯å¢ƒå˜é‡ (æ¨è)
export OPENAI_API_KEY="your-key"
export OPENAI_API_MODEL="gpt-4o-mini"
python -m ck_pro --input "Hello world"

# æ–¹å¼2: æœ€å°é…ç½®
cp config.minimal.toml config.toml
# ç¼–è¾‘APIå¯†é’¥
python -m ck_pro --config config.toml --input "Hello world"
```

### åœºæ™¯2: å¤šæ¨¡å‹é…ç½®
```toml
[ck.model]
call_target = "https://api.openai.com/v1/chat/completions"
api_key = "openai-key"
model = "gpt-4o-mini"

[web.model]
call_target = "https://api.siliconflow.cn/v1/chat/completions"
api_key = "siliconflow-key"
model = "Kimi-K2-Instruct"

[file.model]
call_target = "https://api-inference.modelscope.cn/v1/chat/completions"
api_key = "modelscope-key"
model = "Qwen/Qwen3-235B-A22B-Instruct-2507"
```

### åœºæ™¯3: ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
```bash
# Dockerç¯å¢ƒå˜é‡æ³¨å…¥
docker run -e OPENAI_API_KEY="prod-key" \
           -e OPENAI_API_MODEL="gpt-4o" \
           cognitivekernel-pro

# Kubernetes ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: ck-config
data:
  OPENAI_API_BASE: "https://api.openai.com/v1/chat/completions"
  OPENAI_API_MODEL: "gpt-4o"
```

## â“ å¸¸è§é—®é¢˜

### Q: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ä¼šæ€æ ·ï¼Ÿ
A: ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–ç¡¬ç¼–ç é»˜è®¤å€¼ï¼Œä¸ä¼šå‡ºç°é”™è¯¯ã€‚

### Q: å¦‚ä½•éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ
A: è¿è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•ï¼š`python -m ck_pro --input "test"`

### Q: æ”¯æŒå“ªäº›æ¨¡å‹ï¼Ÿ
A: æ”¯æŒæ‰€æœ‰å…¼å®¹OpenAI APIæ ¼å¼çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬GPTã€Claudeã€Qwenç­‰ã€‚

### Q: å¦‚ä½•åˆ‡æ¢ä¸åŒçš„æ¨¡å‹é…ç½®ï¼Ÿ
A: ä¿®æ”¹`config.toml`ä¸­çš„`[ck.model]`ã€`[web.model]`ã€`[file.model]`éƒ¨åˆ†ã€‚

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [readme.md](readme.md) - é¡¹ç›®ä¸»è¦æ–‡æ¡£
- [docs/ARCH.md](docs/ARCH.md) - æ¶æ„è®¾è®¡æ–‡æ¡£
- [docs/PLAYWRIGHT_BUILTIN.md](docs/PLAYWRIGHT_BUILTIN.md) - Webè‡ªåŠ¨åŒ–æ–‡æ¡£